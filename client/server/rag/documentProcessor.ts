/**
 * DOCUMENT PROCESSOR
 *
 * OPPITUNTI: Miksi tarvitaan chunking?
 * ------------------------------------
 * AI-malleilla on rajallinen konteksti:
 * - GPT-4: 128k tokenia = ~300 sivua tekstiÃ¤
 * - Mutta: paras tarkkuus < 10k tokenia
 * - Ratkaisu: Pilko dokumentti pienempiin osiin
 *
 * CHUNKING STRATEGIAT:
 * 1. Fixed-size: 500 sanaa per chunk (yksinkertainen)
 * 2. Recursive: Kokeile eri separaattoreita (\n\n, \n, ., " ")
 * 3. Semantic: Pilko merkityksellisiin osiin (paragit, otsikot)
 *
 * MIKSI OVERLAP?
 * - EstÃ¤Ã¤ kontekstin katoamisen chunk-rajoilla
 * - Esim: "...liikevaihto oli | 2.1M euroa..."
 *          chunk 1 â†‘       chunk 2 â†‘
 * - Overlap varmistaa molemmat chunkit sisÃ¤ltÃ¤vÃ¤t koko lauseen
 */

import { RecursiveCharacterTextSplitter } from "langchain/text_splitter";
import type { Document } from "./vectorStore.js";
import pdfParse from "pdf-parse";

/**
 * Chunking-konfiguraatio
 *
 * OPPITUNTI: Parametrit
 * - chunkSize: Chunkin maksimikoko merkeissÃ¤
 * - chunkOverlap: Kuinka paljon chunkit menevÃ¤t pÃ¤Ã¤llekkÃ¤in
 * - separators: MissÃ¤ jÃ¤rjestyksessÃ¤ kokeillaan pilkkoa tekstiÃ¤
 *
 * TUOTANTO-OPTIMOINNIT:
 * - Pienet chunkit (500-1000): Tarkempi haku, mutta enemmÃ¤n chunkeja
 * - Isot chunkit (2000-4000): VÃ¤hemmÃ¤n API-kutsuja, mutta epÃ¤tarkempi
 */
export interface ChunkingConfig {
  chunkSize: number;
  chunkOverlap: number;
  separators?: string[];
}

const DEFAULT_CONFIG: ChunkingConfig = {
  chunkSize: 2000, // ~500 sanaa
  chunkOverlap: 200, // 10% overlap
  separators: ["\n\n", "\n", ". ", " ", ""], // Kokeile tÃ¤ssÃ¤ jÃ¤rjestyksessÃ¤
};

/**
 * Pilko teksti chunkeihin
 *
 * OPPITUNTI: RecursiveCharacterTextSplitter
 * - LangChain:n sisÃ¤Ã¤nrakennettu splitter
 * - Kokeilee separaattoreita jÃ¤rjestyksessÃ¤
 * - Varmistaa ettei ylitÃ¤ chunkSize:a
 * - LisÃ¤Ã¤ overlap automaattisesti
 */
export async function chunkText(
  text: string,
  config: ChunkingConfig = DEFAULT_CONFIG
): Promise<string[]> {
  const splitter = new RecursiveCharacterTextSplitter({
    chunkSize: config.chunkSize,
    chunkOverlap: config.chunkOverlap,
    separators: config.separators,
  });

  const chunks = await splitter.splitText(text);

  console.log(
    `ðŸ“„ Chunked text: ${text.length} chars â†’ ${chunks.length} chunks ` +
    `(avg ${Math.round(text.length / chunks.length)} chars/chunk)`
  );

  return chunks;
}

/**
 * Parsoi PDF-tiedosto tekstiksi
 *
 * OPPITUNTI: PDF Parsing
 * - pdf-parse poimii tekstin PDF:stÃ¤
 * - Ei toimi skannatuille PDF:ille (tarvitsisi OCR:n)
 * - Palauttaa myÃ¶s metadataa (sivumÃ¤Ã¤rÃ¤, info jne.)
 */
export async function parsePDF(buffer: Buffer): Promise<{
  text: string;
  numPages: number;
  info?: any;
}> {
  const data = await pdfParse(buffer);

  console.log(`ðŸ“‹ PDF parsed: ${data.numpages} pages, ${data.text.length} characters`);

  return {
    text: data.text,
    numPages: data.numpages,
    info: data.info,
  };
}

/**
 * Prosessoi PDF â†’ Chunkit â†’ Dokumentit
 *
 * OPPITUNTI: End-to-end prosessi
 * 1. Parsoi PDF tekstiksi
 * 2. Pilko tekstin chunkeihin
 * 3. Luo Document-objektit metadata:lla
 * 4. Palauta valmiit dokumentit vector storea varten
 */
export async function processPDF(
  buffer: Buffer,
  filename: string,
  config: ChunkingConfig = DEFAULT_CONFIG
): Promise<Document[]> {
  console.log(`\nðŸ”„ Processing PDF: ${filename}`);

  // 1. Parsoi PDF
  const { text, numPages, info } = await parsePDF(buffer);

  // 2. Chunkkaa teksti
  const chunks = await chunkText(text, config);

  // 3. Luo dokumentit
  const documents: Document[] = chunks.map((chunk, index) => ({
    id: `${filename}-chunk-${index}`,
    pageContent: chunk,
    metadata: {
      source: filename,
      chunk: index,
      totalChunks: chunks.length,
      uploadedAt: new Date().toISOString(),
      numPages,
      pdfInfo: info,
    },
  }));

  console.log(`âœ… Created ${documents.length} documents from ${filename}`);

  return documents;
}

/**
 * Prosessoi tekstitiedosto â†’ Chunkit â†’ Dokumentit
 */
export async function processText(
  text: string,
  filename: string,
  config: ChunkingConfig = DEFAULT_CONFIG
): Promise<Document[]> {
  console.log(`\nðŸ”„ Processing text file: ${filename}`);

  // Chunkkaa teksti
  const chunks = await chunkText(text, config);

  // Luo dokumentit
  const documents: Document[] = chunks.map((chunk, index) => ({
    id: `${filename}-chunk-${index}`,
    pageContent: chunk,
    metadata: {
      source: filename,
      chunk: index,
      totalChunks: chunks.length,
      uploadedAt: new Date().toISOString(),
    },
  }));

  console.log(`âœ… Created ${documents.length} documents from ${filename}`);

  return documents;
}

/**
 * Automaattinen tiedostotyyppi-tunnistus ja prosessointi
 */
export async function processFile(
  fileBuffer: Buffer,
  filename: string,
  mimeType?: string,
  config?: ChunkingConfig
): Promise<Document[]> {
  // Tunnista tiedostotyyppi
  const isPDF = filename.toLowerCase().endsWith('.pdf') ||
                mimeType === 'application/pdf';

  if (isPDF) {
    return processPDF(fileBuffer, filename, config);
  } else {
    // Oletetaan tekstitiedosto
    const text = fileBuffer.toString('utf-8');
    return processText(text, filename, config);
  }
}

/**
 * TESTAUS: Kokeile document processor
 */
export async function testDocumentProcessor() {
  console.log("\nðŸ§ª DOCUMENT PROCESSOR TEST\n");

  // 1. Testi: Chunkkaus
  console.log("1ï¸âƒ£ Text chunking test:\n");

  const longText = `
Humm Group Oy on suomalainen asiakaspalveluratkaisu-yhtiÃ¶, joka on perustettu vuonna 2018.

Yrityksen liikevaihto vuonna 2024 oli 2.1 miljoonaa euroa. KÃ¤yttÃ¶kate oli 15% ja nettotulos oli positiivinen ensimmÃ¤istÃ¤ kertaa yrityksen historiassa. TÃ¤mÃ¤ oli merkittÃ¤vÃ¤ saavutus, sillÃ¤ kasvuyhtiÃ¶t usein tekevÃ¤t tappiota alkuvuosina investoidessaan tulevaisuuteen.

AsiakastyytyvÃ¤isyys nousi vuoden aikana merkittÃ¤vÃ¤sti. CSAT-luku parani 7.2:sta 8.5:een, mikÃ¤ on 18% parannus. TÃ¤rkeimmÃ¤t kehityskohteet ovat vasteaikojen lyhentÃ¤minen ja proaktiivisuuden parantaminen asiakaspalvelussa.

AI-transformaation tavoitteena on automatisoida 40% rutiinitehtÃ¤vistÃ¤ vuoden 2025 loppuun mennessÃ¤. Tavoitteena on myÃ¶s parantaa asiakaskokemusta 25% ja vÃ¤hentÃ¤Ã¤ tukipyyntÃ¶jen mÃ¤Ã¤rÃ¤Ã¤ 30%. NÃ¤mÃ¤ tavoitteet ovat kunnianhimoisia mutta saavutettavissa oikealla teknologialla ja toteutuksella.

Yritys tyÃ¶llistÃ¤Ã¤ tÃ¤llÃ¤ hetkellÃ¤ 25 henkilÃ¶Ã¤ ja suunnittelee kasvattavansa henkilÃ¶stÃ¶Ã¤ 40:een vuoden 2025 loppuun mennessÃ¤. Avainrekrytoinnit keskittyvÃ¤t tekniseen osaamiseen ja AI-spesialisteihin.
  `.trim();

  const chunks = await chunkText(longText, {
    chunkSize: 300,
    chunkOverlap: 50,
  });

  console.log(`Original text: ${longText.length} characters`);
  console.log(`Chunks created: ${chunks.length}\n`);

  chunks.forEach((chunk, i) => {
    console.log(`Chunk ${i + 1} (${chunk.length} chars):`);
    console.log(`"${chunk.substring(0, 100)}..."\n`);
  });

  // 2. Testi: Tekstitiedoston prosessointi
  console.log("\n2ï¸âƒ£ Text file processing test:\n");

  const documents = await processText(longText, "humm_overview_2024.txt", {
    chunkSize: 300,
    chunkOverlap: 50,
  });

  console.log(`\nCreated documents:`);
  documents.forEach((doc, i) => {
    console.log(`\n  Document ${i + 1}:`);
    console.log(`    ID: ${doc.id}`);
    console.log(`    Content: "${doc.pageContent.substring(0, 80)}..."`);
    console.log(`    Metadata: ${JSON.stringify(doc.metadata, null, 6)}`);
  });

  console.log("\nâœ… Test completed!");
  console.log("\nðŸ“š OPPITUNTI:");
  console.log("   - Chunking pilkkoo pitkÃ¤t tekstit hallittaviin osiin");
  console.log("   - Overlap varmistaa kontekstin sÃ¤ilymisen");
  console.log("   - Metadata auttaa jÃ¤ljittÃ¤mÃ¤Ã¤n lÃ¤hteet");
}

// Aja testi jos tiedosto suoritetaan directly
if (import.meta.url === `file://${process.argv[1]}`) {
  testDocumentProcessor().catch(console.error);
}
